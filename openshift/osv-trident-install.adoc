---
sidebar: sidebar 
permalink: openshift/osv-trident-install.html 
keywords: OpenShift, OCP, Trident, Trident protect, NetApp ONTAP, Red Hat OpenShift, OpenShift Virtualization, Red Hat OpenShift Virtualization 
summary: NetApp ONTAP 통한 Red Hat OpenShift 가상화 
---
= Red Hat OpenShift 클러스터에 Trident 설치하고 스토리지 객체를 생성합니다.
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
OpenShift 클러스터에 Red Hat Certified Trident Operator를 사용하여 Trident 설치하고 블록 액세스를 위해 작업자 노드를 준비합니다.  ONTAP 및 FSxN 스토리지에 대한 Trident 백엔드 및 스토리지 클래스 객체를 생성하여 컨테이너 및 VM에 대한 동적 볼륨 프로비저닝을 활성화합니다.


NOTE: OpenShift Virtualization에서 VM을 생성해야 하는 경우 Trident 설치해야 하며 백엔드 개체와 스토리지 클래스 개체를 OpenShift Virtualization을 클러스터(온프레미스 및 ROSA)에 설치하기 전에 OpenShift 클러스터에 생성해야 합니다.  기본 스토리지 클래스와 기본 볼륨 스냅샷 클래스는 클러스터의 Trident 스토리지와 스냅샷 클래스로 설정해야 합니다.  이것이 구성된 경우에만 OpenShift Virtualization은 템플릿을 사용하여 VM을 생성하기 위해 골든 이미지를 로컬로 제공할 수 있습니다.


NOTE: Trident 설치하기 전에 OpenShift Virtualization operator가 설치되어 있는 경우 다음 명령을 사용하여 다른 스토리지 클래스를 사용하여 생성된 골든 이미지를 삭제한 다음, Trident 스토리지 및 볼륨 스냅샷 클래스 기본값이 설정되어 있는지 확인하여 OpenShift Virtualization이 Trident 스토리지 클래스를 사용하여 골든 이미지를 생성하도록 할 수 있습니다.

[source, yaml]
----
oc delete dv,VolumeSnapshot -n openshift-virtualization-os-images --selector=cdi.kubevirt.io/dataImportCron
----

NOTE: ROSA 클러스터의 FSxN 스토리지에 대한 트라이던트 객체를 생성하기 위한 샘플 YAML 파일을 얻고, VolumeSnapshotClass에 대한 샘플 YAML 파일을 얻으려면 이 페이지를 아래로 스크롤하세요.

** Trident 설치**

.Red Hat Certified Operator를 사용하여 Trident 설치
[%collapsible%open]
====
이 섹션에서는 Red Hat Certified Trident Operator를 사용하여 Trident 설치하는 방법에 대한 세부 정보를 제공합니다.link:https://docs.netapp.com/us-en/trident/trident-get-started/kubernetes-deploy.html["Trident 문서를 참조하세요"] Trident 설치하는 다른 방법은 여기를 참조하세요.  Trident 25.02가 출시됨에 따라 온프레미스 및 클라우드의 Red Hat OpenShift에서 Trident 사용하는 사용자와 AWS의 Red Hat OpenShift Service와 같은 관리형 서비스를 사용하는 사용자는 이제 Operator Hub의 Trident Certified Operator를 사용하여 Trident 설치할 수 있습니다.  Trident 이전에는 커뮤니티 운영자로만 제공되었기 때문에 이는 OpenShift 사용자 커뮤니티에 중요한 의미를 갖습니다.

Red Hat Certified Trident 운영자의 장점은 OpenShift와 함께 사용할 경우(온프레미스, 클라우드 또는 ROSA를 통한 관리형 서비스로 사용) NetApp 에서 운영자와 컨테이너의 기반을 완벽하게 지원한다는 것입니다.  또한 NetApp Trident 고객에게 무료로 제공되므로 Red Hat OpenShift와 원활하게 작동하도록 검증된 인증 운영자를 사용하여 설치하기만 하면 되며 간편한 수명 주기 관리를 위해 패키지로 제공됩니다.

또한, Trident 25.02 운영자(및 이후 버전)는 iSCSI를 위한 작업자 노드를 준비하는 선택적 이점을 제공합니다.  특히 ROSA 클러스터에 워크로드를 배포하고 FSxN과 함께 iSCSI 프로토콜을 사용하려는 경우 이 기능이 매우 유용합니다. 특히 OpenShift Virtualization VM 워크로드에 유용합니다.  FSxN을 사용하여 ROSA 클러스터에서 iSCSI를 위한 워커 노드를 준비하는 과제는 클러스터에 Trident 설치하면 이 기능으로 완화됩니다.

운영자를 사용하는 설치 단계는 온프레미스 클러스터에 설치하든 ROSA에 설치하든 동일합니다.  Operator를 사용하여 Trident 설치하려면 Operator 허브를 클릭하고 Certified NetApp Trident 선택하세요.  설치 페이지에서는 기본적으로 최신 버전이 선택되어 있습니다.  설치를 클릭하세요.image:rh-os-n-use-case-osv-trident-install-001.png["운영자 허브"]

image:rh-os-n-use-case-osv-trident-install-002.png["설치하다"]

운영자가 설치되면 운영자 보기를 클릭한 다음 Trident Orchestrator의 인스턴스를 만듭니다.  iSCSI 스토리지 액세스를 위해 작업자 노드를 준비하려면 YAML 보기로 이동하여 iscsi를 추가하여 nodePrep 매개변수를 수정합니다.

image:rh-os-n-use-case-osv-trident-install-003.png["노드 준비를 위해 iSCSI를 추가합니다."]

이제 클러스터에서 모든 트라이던트 포드가 실행 중이어야 합니다.image:rh-os-n-use-case-osv-trident-install-004.png["Trident 설치됨"]

OpenShift 클러스터의 작업자 노드에서 iSCSI 도구가 활성화되었는지 확인하려면 작업자 노드에 로그인하여 표시된 대로 iscsid, multipathd active 및 multipath.conf 파일의 항목을 확인하세요.

image:rh-os-n-use-case-osv-trident-install-005.png["iscsid 실행 중"]

image:rh-os-n-use-case-osv-trident-install-006.png["multipathd 실행 중"]

image:rh-os-n-use-case-osv-trident-install-007.png["multipathconf 파일 실행 중"]

====


== 비디오 데모

다음 비디오는 Red Hat Certified Trident Operator를 사용하여 Trident 설치하는 방법을 보여줍니다.

.OpenShift에서 인증된 Trident Operator를 사용하여 Trident 25.02.1 설치
video::15c225f3-13ef-41ba-b255-b2d500f927c0[panopto,width=360]


== 온프레미스 OpenShift 클러스터를 위한 Trident 구성

.NAS용 Trident 백엔드 및 스토리지 클래스
[%collapsible%open]
====
[source, yaml]
----
cat tbc-nas.yaml
apiVersion: v1
kind: Secret
metadata:
  name: tbc-nas-secret
type: Opaque
stringData:
  username: <cluster admin username>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: tbc-nas
spec:
  version: 1
  storageDriverName: ontap-nas
  managementLIF: <cluster management lif>
  backendName: tbc-nas
  svm: zoneb
  storagePrefix: testzoneb
  defaults:
    nameTemplate: "{{ .config.StoragePrefix }}_{{ .volume.Namespace }}_{{ .volume.RequestName }}"
  credentials:
    name: tbc-nas-secret
----
[source, yaml]
----
cat sc-nas.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-nas
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-nas"
  media: "ssd"
  provisioningType: "thin"
  snapshots: "true"
allowVolumeExpansion: true
----
====
.iSCSI를 위한 Trident 백엔드 및 스토리지 클래스
[%collapsible%open]
====
[source, yaml]
----
# cat tbc-iscsi.yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-tbc-ontap-iscsi-secret
type: Opaque
stringData:
  username: <cluster admin username>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: ontap-iscsi
spec:
  version: 1
  storageDriverName: ontap-san
  managementLIF: <management LIF>
  backendName: ontap-iscsi
  svm: <SVM name>
  credentials:
    name: backend-tbc-ontap-iscsi-secret
----
[source, yaml]
----
# cat sc-iscsi.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-iscsi
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-san"
  media: "ssd"
  provisioningType: "thin"
  fsType: ext4
  snapshots: "true"
allowVolumeExpansion: true
----
====
.NVMe/TCP를 위한 Trident 백엔드 및 스토리지 클래스
[%collapsible%open]
====
[source, yaml]
----
# cat tbc-nvme.yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-tbc-ontap-nvme-secret
type: Opaque
stringData:
  username: <cluster admin password>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: backend-tbc-ontap-nvme
spec:
  version: 1
  storageDriverName: ontap-san
  managementLIF: <cluster management LIF>
  backendName: backend-tbc-ontap-nvme
  svm: <SVM name>
  credentials:
    name: backend-tbc-ontap-nvme-secret
----
[source, yaml]
----
# cat sc-nvme.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-nvme
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-san"
  media: "ssd"
  provisioningType: "thin"
  fsType: ext4
  snapshots: "true"
allowVolumeExpansion: true
----
====
.FC용 Trident 백엔드 및 스토리지 클래스
[%collapsible%open]
====
[source, yaml]
----
# cat tbc-fc.yaml
apiVersion: v1
kind: Secret
metadata:
  name: tbc-fc-secret
type: Opaque
stringData:
  username: <cluster admin password>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: tbc-fc
spec:
  version: 1
  storageDriverName: ontap-san
  managementLIF: <cluster mgmt lif>
  backendName: tbc-fc
  svm: openshift-fc
  sanType: fcp
  storagePrefix: demofc
  defaults:
    nameTemplate: "{{ .config.StoragePrefix }}_{{ .volume.Namespace }}_{{ .volume.RequestName }}"
  credentials:
    name: tbc-fc-secret
----
[source, yaml]
----
# cat sc-fc.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-fc
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-san"
  media: "ssd"
  provisioningType: "thin"
  fsType: ext4
  snapshots: "true"
allowVolumeExpansion: true
----
====


== FSxN 스토리지를 사용한 ROSA 클러스터에 대한 Trident 구성

.FSxN NAS를 위한 Trident 백엔드 및 스토리지 클래스
[%collapsible%open]
====
[source, yaml]
----
#cat tbc-fsx-nas.yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-fsx-ontap-nas-secret
  namespace: trident
type: Opaque
stringData:
  username: <cluster admin lif>
  password: <cluster admin passwd>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: backend-fsx-ontap-nas
  namespace: trident
spec:
  version: 1
  backendName: fsx-ontap
  storageDriverName: ontap-nas
  managementLIF: <Management DNS name>
  dataLIF: <NFS DNS name>
  svm: <SVM NAME>
  credentials:
    name: backend-fsx-ontap-nas-secret
----
[source, yaml]
----
# cat sc-fsx-nas.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: trident-csi
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-nas"
  fsType: "ext4"
allowVolumeExpansion: True
reclaimPolicy: Retain
----
====
.FSxN iSCSI를 위한 Trident 백엔드 및 스토리지 클래스
[%collapsible%open]
====
[source, yaml]
----
# cat tbc-fsx-iscsi.yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-tbc-fsx-iscsi-secret
type: Opaque
stringData:
  username: <cluster admin username>
  password: <cluster admin password>
---
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: fsx-iscsi
spec:
  version: 1
  storageDriverName: ontap-san
  managementLIF: <management LIF>
  backendName: fsx-iscsi
  svm: <SVM name>
  credentials:
    name: backend-tbc-ontap-iscsi-secret
----
[source, yaml]
----
# cat sc-fsx-iscsi.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-fsx-iscsi
provisioner: csi.trident.netapp.io
parameters:
  backendType: "ontap-san"
  media: "ssd"
  provisioningType: "thin"
  fsType: ext4
  snapshots: "true"
allowVolumeExpansion: true
----
====


== Trident 볼륨 스냅샷 클래스 생성

.Trident 볼륨 스냅샷 클래스
[%collapsible%open]
====
[source, yaml]
----
# cat snapshot-class.yaml
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: trident-snapshotclass
driver: csi.trident.netapp.io
deletionPolicy: Retain
----
====
백엔드 구성, 스토리지 클래스 구성 및 스냅샷 구성에 필요한 yaml 파일을 준비한 후 다음 명령을 사용하여 trident 백엔드, 스토리지 클래스 및 스냅샷 클래스 객체를 생성할 수 있습니다.

[source, yaml]
----
oc create -f <backend-filename.yaml> -n trident
oc create -f < storageclass-filename.yaml>
oc create -f <snapshotclass-filename.yaml>
----


== Trident Storage 및 Snapshot Class를 사용하여 기본값 설정

.Trident Storage 및 Snapshot Class를 사용하여 기본값 설정
[%collapsible%open]
====
이제 OpenShift 클러스터에서 필수 Trident 스토리지 클래스와 볼륨 스냅샷 클래스를 기본값으로 만들 수 있습니다.  앞서 언급했듯이 기본 스토리지 클래스와 볼륨 스냅샷 클래스를 설정해야 OpenShift Virtualization에서 골든 이미지 소스를 사용하여 기본 템플릿에서 VM을 생성할 수 있습니다.

콘솔에서 주석을 편집하거나 다음 명령어를 사용하여 명령줄에서 패치를 적용하여 Trident 스토리지 클래스와 스냅샷 클래스를 기본값으로 설정할 수 있습니다.

[source, yaml]
----
storageclass.kubernetes.io/is-default-class:true
or
kubectl patch storageclass standard -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

storageclass.kubevirt.io/is-default-virt-class: true
or
kubectl patch storageclass standard -p '{"metadata": {"annotations":{"storageclass.kubevirt.io/is-default-virt-class": "true"}}}'
----
이것이 설정되면 다음 명령을 사용하여 기존 dv 및 VolumeSnapShot 개체를 삭제할 수 있습니다.

[source, yaml]
----
oc delete dv,VolumeSnapshot -n openshift-virtualization-os-images --selector=cdi.kubevirt.io/dataImportCron
----
====