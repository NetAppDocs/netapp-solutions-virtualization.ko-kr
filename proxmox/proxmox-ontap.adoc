---
sidebar: sidebar 
permalink: proxmox/proxmox-ontap.html 
keywords: netapp, proxmox, proxmox ve, all-flash, nfs, iscsi, ontap, storage, aff 
summary: 'Proxmox Virtual Environment(VE)의 공유 스토리지는 VM 라이브 마이그레이션에 소요되는 시간을 줄이고, 환경 전반에 걸쳐 백업과 일관된 템플릿을 위한 더 나은 대상을 제공합니다.  ONTAP 스토리지는 Proxmox VE 호스트 환경의 요구 사항뿐만 아니라 게스트 파일, 블록 및 개체 스토리지 요구 사항도 충족할 수 있습니다.' 
---
= Proxmox 가상 환경에 대한 ONTAP 스토리지 프로비저닝
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
NAS, SAN, SMB/CIFS 프로토콜을 사용하여 Proxmox 가상 환경(VE)으로 ONTAP 스토리지를 구성합니다.  Proxmox VE의 공유 스토리지는 라이브 VM 마이그레이션에 소요되는 시간을 줄이고, 환경 전반에 걸쳐 백업을 위한 더 나은 대상과 일관된 템플릿을 제공합니다.

Proxmox VE 호스트에는 스위치에 케이블로 연결된 FC, 이더넷 또는 기타 지원 인터페이스가 있어야 하며 ONTAP 논리 인터페이스와 통신할 수 있어야 합니다.  항상 확인하세요 https://mysupport.netapp.com/matrix/#welcome["상호 운용성 매트릭스 도구"] 지원되는 구성에 대해서는.



== 고급 ONTAP 기능

*공통적인 특징*

* 스케일 아웃 클러스터
* 보안 인증 및 RBAC 지원
* 제로 트러스트 다중 관리자 지원
* 보안 멀티테넌시
* SnapMirror 사용하여 데이터를 복제합니다.
* 스냅샷을 이용한 특정 시점의 사본.
* 공간 효율적인 클론.
* 중복 제거, 압축 등의 저장 효율성 기능
* Kubernetes에 대한 Trident CSI 지원
* 스냅락
* 변조 방지 스냅샷 복사 잠금
* 암호화 지원
* FabricPool 사용하여 콜드 데이터를 객체 저장소로 계층화합니다.
* BlueXP 와 CloudInsights 통합.
* Microsoft 오프로드 데이터 전송(ODX)


*나스*

* FlexGroup 볼륨은 확장 가능한 NAS 컨테이너로, 부하 분산 및 확장성과 함께 높은 성능을 제공합니다.
* FlexCache 사용하면 데이터를 전 세계적으로 분산할 수 있으며, 여전히 로컬에서 데이터에 대한 읽기 및 쓰기 액세스를 제공합니다.
* 다중 프로토콜 지원을 통해 SMB뿐만 아니라 NFS를 통해서도 동일한 데이터에 접근할 수 있습니다.
* NFS nConnect는 TCP 연결당 여러 TCP 세션을 허용하여 네트워크 처리량을 증가시킵니다.  이를 통해 최신 서버에서 사용할 수 있는 고속 NIC의 활용도가 높아집니다.
* NFS 세션 트렁킹은 데이터 전송 속도를 높이고, 가용성을 높이며, 내결함성을 제공합니다.
* SMB 다중채널은 향상된 데이터 전송 속도, 높은 가용성 및 내결함성을 제공합니다.
* 파일 권한을 위한 Active Directory/LDAP와의 통합.
* TLS를 통한 NFS로 안전하게 연결합니다.
* NFS Kerberos 지원.
* RDMA를 통한 NFS.
* Windows와 Unix ID 간 이름 매핑.
* 자율적인 랜섬웨어 보호.
* 파일 시스템 분석.


*산*

* SnapMirror 액티브 동기화를 통해 오류 도메인 전반에 걸쳐 클러스터를 확장합니다. 항상 확인하세요 https://mysupport.netapp.com/matrix/#welcome["상호 운용성 매트릭스 도구"] 지원되는 구성에 대해서는.
* ASA 모델은 액티브/액티브 멀티패스와 빠른 경로 장애 조치를 제공합니다.
* FC, iSCSI, NVMe-oF 프로토콜 지원.
* iSCSI CHAP 상호 인증 지원.
* 선택적 LUN 맵 및 포트셋.




== ONTAP 에서 지원되는 Proxmox VE 스토리지 유형

NAS 프로토콜(NFS/SMB)은 Proxmox VE의 모든 콘텐츠 유형을 지원하며 일반적으로 데이터 센터 수준에서 한 번 구성됩니다.  게스트 VM은 NAS 스토리지에서 raw, qcow2 또는 VMDK 유형의 디스크를 사용할 수 있습니다.  ONTAP 스냅샷을 표시하여 클라이언트의 데이터 사본을 특정 시점에 액세스할 수 있습니다.  SAN 프로토콜(FC/iSCSI/NVMe-oF)을 사용하는 블록 스토리지는 일반적으로 호스트별로 구성되며 Proxmox VE에서 지원하는 VM 디스크 및 컨테이너 이미지 콘텐츠 유형으로 제한됩니다.  게스트 VM과 컨테이너는 블록 스토리지를 원시 장치로 사용합니다.

[cols="25% 15% 15% 15% 15% 15%"]
|===
| 콘텐츠 유형 | NFS | SMB/CIFS | FC | iSCSI | NVMe-oF 


| 백업 | 예 | 예  a| 
아니요^1^
 a| 
아니요^1^
 a| 
아니요^1^



| VM 디스크 | 예 | 예  a| 
네^2^
 a| 
네^2^
 a| 
네^2^



| CT 볼륨 | 예 | 예  a| 
네^2^
 a| 
네^2^
 a| 
네^2^



| ISO 이미지 | 예 | 예  a| 
아니요^1^
 a| 
아니요^1^
 a| 
아니요^1^



| CT 템플릿 | 예 | 예  a| 
아니요^1^
 a| 
아니요^1^
 a| 
아니요^1^



| 짧은 발췌 | 예 | 예  a| 
아니요^1^
 a| 
아니요^1^
 a| 
아니요^1^

|===
*참고:* 1 - 공유 폴더를 생성하고 디렉토리 저장 유형을 사용하려면 클러스터 파일 시스템이 필요합니다.  2 - LVM 저장 유형을 사용합니다.



== SMB/CIFS 스토리지

SMB/CIFS 파일 공유를 활용하려면 스토리지 관리자가 수행해야 하는 특정 작업이 있으며, 가상화 관리자는 Proxmox VE UI나 셸을 사용하여 공유를 마운트할 수 있습니다.  SMB 다중채널은 장애 내구성을 제공하고 성능을 향상시킵니다.  자세한 내용은 다음을 참조하세요.link:https://www.netapp.com/pdf.html?item=/media/17136-tr4740.pdf["TR4740 - SMB 3.0 멀티채널"]


NOTE: 비밀번호는 일반 텍스트 파일로 저장되며 루트 사용자만 접근할 수 있습니다. link:https://pve.proxmox.com/pve-docs/chapter-pvesm.html#storage_cifs["Proxmox VE 문서"] .

.ONTAP 사용한 SMB 공유 스토리지 풀
video::5b4ae54a-08d2-4f7d-95ec-b22d015f6035[panopto,width=360]
.<strong>저장소 관리 작업</strong>
[%collapsible%open]
====
ONTAP 처음 사용하는 경우 시스템 관리자 인터페이스를 사용하여 이러한 작업을 완료하면 더 나은 환경을 경험할 수 있습니다.

. SMB에 대해 SVM이 활성화되어 있는지 확인하세요.  따르다link:https://docs.netapp.com/us-en/ontap/smb-config/configure-access-svm-task.html["ONTAP 9 문서"] 자세한 내용은.
. 컨트롤러당 최소 2개의 생명을 가져야 합니다.  위 링크의 단계를 따르세요.  참고로, 이 솔루션에 사용된 lifs의 스크린샷은 다음과 같습니다.
+
image:proxmox-ontap-001.png["NAS 인터페이스 세부 정보"]

. Active Directory 또는 작업 그룹 기반 인증을 사용하세요.  위 링크의 단계를 따르세요.
+
image:proxmox-ontap-002.png["도메인 정보 가입"]

. 볼륨을 생성합니다.  FlexGroup 사용하려면 클러스터 전체에 데이터를 분산하는 옵션을 선택하는 것을 잊지 마세요.
+
image:proxmox-ontap-023.png["FlexGroup 옵션"]

. SMB 공유를 만들고 권한을 조정합니다.  따르다link:https://docs.netapp.com/us-en/ontap/smb-config/configure-client-access-shared-storage-concept.html["ONTAP 9 문서"] 자세한 내용은.
+
image:proxmox-ontap-003.png["SMB 공유 정보"]

. 가상화 관리자가 작업을 완료할 수 있도록 SMB 서버, 공유 이름 및 자격 증명을 제공합니다.


====
.<strong>가상화 관리 작업</strong>
[%collapsible%open]
====
. 공유 인증에 사용할 SMB 서버, 공유 이름 및 자격 증명을 수집합니다.
. 최소 두 개의 인터페이스가 서로 다른 VLAN에 구성되어 있고(장애 허용을 위해) NIC가 RSS를 지원하는지 확인하세요.
. 관리 UI를 사용하는 경우 `https:<proxmox-node>:8006` , 데이터 센터를 클릭하고, 저장소를 선택하고, 추가를 클릭한 다음 SMB/CIFS를 선택합니다.
+
image:proxmox-ontap-004.png["SMB 스토리지 탐색"]

. 세부 정보를 입력하면 공유 이름이 자동으로 채워집니다.  모든 콘텐츠가 선택되었는지 확인하세요.  추가를 클릭하세요.
+
image:proxmox-ontap-005.png["SMB 스토리지 추가"]

. 다중 채널 옵션을 활성화하려면 클러스터의 노드 중 하나에서 셸로 이동하여 pvesm set pvesmb01 --options multichannel,max_channels=4를 입력합니다.
+
image:proxmox-ontap-006.png["다중 채널 설정"]

. 위 작업에 대한 /etc/pve/storage.cfg의 내용은 다음과 같습니다.
+
image:proxmox-ontap-007.png["SMB용 스토리지 구성 파일"]



====


== NFS 스토리지

ONTAP Proxmox VE가 지원하는 모든 NFS 버전을 지원합니다.  결함 허용성과 성능 향상을 제공하려면 다음을 확인하십시오.link:https://docs.netapp.com/us-en/ontap/nfs-trunking/index.html["세션 트렁킹"] 활용됩니다.  세션 트렁킹을 사용하려면 최소 NFS v4.1이 필요합니다.

ONTAP 처음 사용하는 경우 시스템 관리자 인터페이스를 사용하여 이러한 작업을 완료하면 더 나은 환경을 경험할 수 있습니다.

.ONTAP 사용한 NFS nconnect 옵션
video::f6c9aba3-b070-45d6-8048-b22e001acfd4[panopto,width=360]
.<strong>저장소 관리 작업</strong>
[%collapsible%open]
====
. NFS에 대해 SVM이 활성화되어 있는지 확인하세요. 다음을 참조하세요. link:https://docs.netapp.com/us-en/ontap/nfs-config/verify-protocol-enabled-svm-task.html["ONTAP 9 문서"]
. 컨트롤러당 최소 2개의 생명을 가져야 합니다.  위 링크의 단계를 따르세요.  참고로, 우리 연구실에서 사용하는 lifes의 스크린샷을 올려드립니다.
+
image:proxmox-ontap-001.png["NAS 인터페이스 세부 정보"]

. Proxmox VE 호스트 IP 주소 또는 서브넷에 대한 액세스를 제공하는 NFS 내보내기 정책을 만들거나 업데이트합니다. 참조하다link:https://docs.netapp.com/us-en/ontap/nfs-config/create-export-policy-task.html["수출 정책 생성"] 그리고link:https://docs.netapp.com/us-en/ontap/nfs-config/add-rule-export-policy-task.html["내보내기 정책에 규칙 추가"] .
. link:https://docs.netapp.com/us-en/ontap/nfs-config/create-volume-task.html["볼륨을 생성합니다"] . FlexGroup 사용하려면 클러스터 전체에 데이터를 분산하는 옵션을 선택하는 것을 잊지 마세요.
+
image:proxmox-ontap-023.png["FlexGroup 옵션"]

. link:https://docs.netapp.com/us-en/ontap/nfs-config/associate-export-policy-flexvol-task.html["볼륨에 내보내기 정책 할당"]
+
image:proxmox-ontap-008.png["NFS 볼륨 정보"]

. 가상화 관리자에게 NFS 볼륨이 준비되었음을 알립니다.


====
.<strong>가상화 관리 작업</strong>
[%collapsible%open]
====
. 최소 두 개의 인터페이스가 서로 다른 VLAN에 구성되어 있는지 확인하세요(장애 허용을 위해).  NIC 본딩을 사용하세요.
. 관리 UI를 사용하는 경우 `https:<proxmox-node>:8006` , 데이터 센터를 클릭하고, 저장소를 선택하고, 추가를 클릭한 다음 NFS를 선택합니다.
+
image:proxmox-ontap-009.png["NFS 스토리지 탐색"]

. 세부 정보를 입력하고, 서버 정보를 제공하면 NFS 내보내기가 채워지고 목록에서 선택됩니다.  콘텐츠 옵션을 선택하는 것을 잊지 마세요.
+
image:proxmox-ontap-010.png["NFS 스토리지 추가"]

. nConnect 옵션을 활성화하려면 클러스터의 노드 중 하나에서 셸로 이동하여 pvesm set pvenfs01 --options nconnect=4를 입력합니다. 여기서 pvenfs01은 위 단계에서 만든 스토리지 ID입니다. 트렁킹 기능을 사용하려는 경우 최소한 NFS v4.1을 사용하고 trunkdiscovery 옵션을 설정해야 합니다. pvesm set pvenfs01 --options vers=4.1,trunkdiscovery


====


== iSCSI를 사용한 LVM

.ONTAP 사용하여 iSCSI와 LVM 공유 풀
video::d66ef67f-bcc2-4ced-848e-b22e01588e8c[panopto,width=360]
Proxmox 호스트 간 공유 스토리지에 대한 논리 볼륨 관리자를 구성하려면 다음 작업을 완료하세요.

.<strong>가상화 관리 작업</strong>
[%collapsible%open]
====
. 두 개의 Linux VLAN 인터페이스를 사용할 수 있는지 확인하세요.
. 모든 Proxmox VE 호스트에 multipath-tools가 설치되어 있는지 확인하세요.  부팅 시 시작되는지 확인하세요.
+
[source, shell]
----
apt list | grep multipath-tools
# If need to install, execute the following line.
apt-get install multipath-tools
systemctl enable multipathd
----
. 모든 Proxmox VE 호스트에 대한 iSCSI 호스트 IQN을 수집하여 스토리지 관리자에게 제공합니다.
+
[source, shell]
----
cat /etc/iscsi/initiator.name
----


====
.<strong>저장소 관리 작업</strong>
[%collapsible%open]
====
ONTAP 처음 사용하는 경우 System Manager를 사용하면 더 나은 환경을 경험할 수 있습니다.

. iSCSI 프로토콜이 활성화된 상태에서 SVM을 사용할 수 있는지 확인하세요.  따르다link:https://docs.netapp.com/us-en/ontap/san-admin/provision-storage.html["ONTAP 9 문서"]
. 컨트롤러당 iSCSI에 전용된 두 개의 life를 갖습니다.
+
image:proxmox-ontap-013.png["iSCSI 인터페이스 세부 정보"]

. igroup을 생성하고 호스트 iSCSI 이니시에이터를 채웁니다.
. SVM에서 원하는 크기의 LUN을 생성하고 위 단계에서 생성한 igroup에 표시합니다.
+
image:proxmox-ontap-014.png["iSCSI LUN 세부 정보"]

. LUN이 생성되었음을 가상화 관리자에게 알립니다.


====
.<strong>가상화 관리 작업</strong>
[%collapsible%open]
====
. 관리 UI로 이동 `https:<proxmox node>:8006` , 데이터 센터를 클릭하고, 스토리지를 선택하고, 추가를 클릭한 다음 iSCSI를 선택합니다.
+
image:proxmox-ontap-015.png["iSCSI 스토리지 탐색"]

. 저장소 ID 이름을 제공하세요.  ONTAP 의 iSCSI life 주소는 통신 문제가 없을 때 대상을 선택할 수 있어야 합니다.  게스트 VM에 LUN 액세스를 직접 제공하지 않으려는 의도이므로 해당 설정을 해제하세요.
+
image:proxmox-ontap-016.png["iSCSI 스토리지 유형 생성"]

. 이제 추가를 클릭하고 LVM을 선택하세요.
+
image:proxmox-ontap-017.png["LVM 스토리지 탐색"]

. 저장소 ID 이름을 제공하고, 위 단계에서 생성한 iSCSI 저장소와 일치해야 하는 기본 저장소를 선택합니다.  기본 볼륨에 대한 LUN을 선택합니다.  볼륨 그룹 이름을 제공합니다.  공유가 선택되어 있는지 확인하세요.
+
image:proxmox-ontap-018.png["lvm 스토리지 생성"]

. iSCSI 볼륨을 사용하는 LVM에 대한 샘플 스토리지 구성 파일은 다음과 같습니다.
+
image:proxmox-ontap-019.png["lvm iscsi 구성"]



====


== NVMe/TCP를 사용한 LVM

.ONTAP 사용하여 NVMe/TCP와 LVM 공유 풀을 생성합니다.
video::80164fe4-06db-4c21-a25d-b22e0179c3d2[panopto,width=360]
Proxmox 호스트 간 공유 스토리지에 대한 논리 볼륨 관리자를 구성하려면 다음 작업을 완료하세요.

.<strong>가상화 관리 작업</strong>
[%collapsible%open]
====
. 두 개의 Linux VLAN 인터페이스를 사용할 수 있는지 확인하세요.
. 클러스터의 모든 Proxmox 호스트에서 다음 명령을 실행하여 호스트 개시자 정보를 수집합니다.
+
[source, shell]
----
nvme show-hostnqn
----
. 수집된 호스트 nqn 정보를 스토리지 관리자에게 제공하고 필요한 크기의 nvme 네임스페이스를 요청합니다.


====
.<strong>저장소 관리 작업</strong>
[%collapsible%open]
====
ONTAP 처음 사용하는 경우 System Manager를 사용하면 더 나은 환경을 경험할 수 있습니다.

. NVMe 프로토콜이 활성화된 상태에서 SVM을 사용할 수 있는지 확인하세요.  나타내다link:https://docs.netapp.com/us-en/ontap/san-admin/create-nvme-namespace-subsystem-task.html["ONTAP 9 문서의 NVMe 작업"] .
. NVMe 네임스페이스를 생성합니다.
+
image:proxmox-ontap-020.png["nvme 네임스페이스 생성"]

. 하위 시스템을 생성하고 호스트 nqns를 할당합니다(CLI를 사용하는 경우).  위의 참조 링크를 따라가세요.
. 가상화 관리자에게 NVME 네임스페이스가 생성되었음을 알립니다.


====
.<strong>가상화 관리 작업</strong>
[%collapsible%open]
====
. 클러스터의 각 Proxmox VE 호스트에서 셸로 이동하여 /etc/nvme/discovery.conf 파일을 만들고 사용자 환경에 맞게 콘텐츠를 업데이트합니다.
+
[source, shell]
----
root@pxmox01:~# cat /etc/nvme/discovery.conf
# Used for extracting default parameters for discovery
#
# Example:
# --transport=<trtype> --traddr=<traddr> --trsvcid=<trsvcid> --host-traddr=<host-traddr> --host-iface=<host-iface>

-t tcp -l 1800 -a 172.21.118.153
-t tcp -l 1800 -a 172.21.118.154
-t tcp -l 1800 -a 172.21.119.153
-t tcp -l 1800 -a 172.21.119.154
----
. NVMe 서브시스템에 로그인
+
[source, shell]
----
nvme connect-all
----
. 장치 세부 정보를 검사하고 수집합니다.
+
[source, shell]
----
nvme list
nvme netapp ontapdevices
nvme list-subsys
lsblk -l
----
. 볼륨 그룹 생성
+
[source, shell]
----
vgcreate pvens02 /dev/mapper/<device id>
----
. 관리 UI로 이동 `https:<proxmox node>:8006` , 데이터 센터를 클릭하고, 스토리지를 선택하고, 추가를 클릭한 다음 LVM을 선택합니다.
+
image:proxmox-ontap-017.png["LVM 스토리지 탐색"]

. 저장소 ID 이름을 제공하고, 기존 볼륨 그룹을 선택한 다음, CLI로 방금 만든 볼륨 그룹을 선택합니다.  공유 옵션을 확인하세요.
+
image:proxmox-ontap-021.png["기존 vg에 lvm 설치"]

. 다음은 NVMe/TCP를 사용하는 LVM에 대한 샘플 스토리지 구성 파일입니다.
+
image:proxmox-ontap-022.png["NVMe TCP 구성의 LVM"]



====